{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "217835e1-41b4-4c53-9cb6-683baac2f030",
   "metadata": {},
   "source": [
    "# distilEfficientFaceNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5d76b3d-b9ca-45b7-ac1d-865ae5c8649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, copy\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56ae742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'distilEfficientFaceNet - run6'\n",
    "\n",
    "IMG_SHAPE = (224, 224, 3)\n",
    "IMG_SIZE = IMG_SHAPE[:-1]\n",
    "\n",
    "TEST_SIZE = 0.1\n",
    "VAL_SIZE = 0.1\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "INITIAL_LR = 1e-3\n",
    "\n",
    "BASE_PATH = 'C:/Users/ngwei/Desktop/ITI110 Deep Learning Project'\n",
    "DATASET_PATH = os.path.join(BASE_PATH, 'data', 'main')\n",
    "FACENET_EMBEDDING_PATH = os.path.join(BASE_PATH, 'data', 'facenet_embedding')\n",
    "MODEL_RUN_PATH = os.path.join(BASE_PATH, 'models', MODEL_NAME)\n",
    "TB_LOG_PATH = os.path.join(BASE_PATH, 'tb_logs', MODEL_NAME)\n",
    "\n",
    "if not os.path.isdir(MODEL_RUN_PATH):\n",
    "    os.mkdir(MODEL_RUN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0fe4a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, save_path=''):\n",
    "    \n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure(figsize=(20,6))\n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label=\"train\")\n",
    "    plt.plot(history.history['val_loss'], label=\"val\")\n",
    "    plt.title(\"Model Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    # summarize history for cosine similarity\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['mse'], label=\"train\")\n",
    "    plt.plot(history.history['val_mse'], label=\"val\")\n",
    "    plt.title(\"Model MSE\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc='upper left')\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeeef47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "\t Number of Classes: 1436\n",
      "\t Number of Images:  21135 \n",
      "\n",
      "Val:\n",
      "\t Number of Classes: 160\n",
      "\t Number of Images:  2759 \n",
      "\n",
      "Test:\n",
      "\t Number of Classes: 178\n",
      "\t Number of Images:  2742 \n",
      "\n",
      "--------------------------------------------------\n",
      "Total:\n",
      "\t Number of Classes: 1774\n",
      "\t Number of Images:  26636\n"
     ]
    }
   ],
   "source": [
    "def load_data(path=DATASET_PATH, test_size=TEST_SIZE, val_size=VAL_SIZE):\n",
    "    \n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = [], [], [], [], [], []\n",
    "    folders = glob(path+'/*')\n",
    "    \n",
    "    # to ensure similar distribution of number of images per class\n",
    "    def get_folder_size_bins(folders):\n",
    "        folders_size = [len(os.listdir(folder)) for folder in folders]\n",
    "        qcut_list = list(pd.qcut(folders_size, 10, duplicates='drop'))\n",
    "        return qcut_list\n",
    "    \n",
    "    test_qualified_folders = [folder for folder in folders if len(os.listdir(folder)) >= 2]\n",
    "    folders_size_bins = get_folder_size_bins(test_qualified_folders)\n",
    "    train_folders, test_folders = train_test_split(test_qualified_folders, stratify=folders_size_bins,\n",
    "                                                   test_size=test_size, random_state=1234)\n",
    "    \n",
    "    folders_size_bins = get_folder_size_bins(train_folders)\n",
    "    train_folders, val_folders = train_test_split(train_folders, stratify=folders_size_bins,\n",
    "                                                  test_size=val_size, random_state=1234)\n",
    "    \n",
    "    label, lbl2name = 0, dict()\n",
    "    for folder in train_folders:\n",
    "        files = glob(folder+'/*')\n",
    "        X_train.extend(files)\n",
    "        y_train.extend([label] * len(files))\n",
    "        lbl2name[label] = os.path.basename(folder)\n",
    "        label += 1\n",
    "    for folder in val_folders:\n",
    "        files = glob(folder+'/*')\n",
    "        X_val.extend(files)\n",
    "        y_val.extend([label] * len(files))\n",
    "        lbl2name[label] = os.path.basename(folder)\n",
    "        label += 1\n",
    "    for folder in test_folders:\n",
    "        files = glob(folder+'/*')\n",
    "        X_test.extend(files)\n",
    "        y_test.extend([label] * len(files))\n",
    "        lbl2name[label] = os.path.basename(folder)\n",
    "        label += 1\n",
    "        \n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "    X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "    \n",
    "    print('Train:')\n",
    "    print('\\t Number of Classes:', len(train_folders))\n",
    "    print('\\t Number of Images: ', len(y_train), '\\n')\n",
    "    print('Val:')\n",
    "    print('\\t Number of Classes:', len(val_folders))\n",
    "    print('\\t Number of Images: ', len(y_val), '\\n')\n",
    "    print('Test:')\n",
    "    print('\\t Number of Classes:', len(test_folders))\n",
    "    print('\\t Number of Images: ', len(y_test), '\\n')\n",
    "    print('-'*50)\n",
    "    print('Total:')\n",
    "    print('\\t Number of Classes:', len(train_folders)+len(val_folders)+len(test_folders))\n",
    "    print('\\t Number of Images: ', len(y_train)+len(y_val)+len(y_test))\n",
    "    \n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test), lbl2name\n",
    "\n",
    "\n",
    "(X_train_paths, y_train_labels), (X_val_paths, y_val_labels), (X_test_paths, y_test_labels), lbl2name = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "555da981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocessing(path):\n",
    "    image = Image.open(path).resize(IMG_SIZE)\n",
    "    image = np.asarray(image).astype(\"float32\")\n",
    "    image = preprocess_input(image, data_format='channels_last')\n",
    "    return image\n",
    "\n",
    "def get_images_from_paths(img_paths, image_preprocessing_fn=image_preprocessing):\n",
    "    images = [image_preprocessing_fn(path) for path in img_paths]\n",
    "    return np.array(images, dtype='float32')\n",
    "\n",
    "def image_facenet_preprocessing(path):\n",
    "    image = Image.open(path).resize((160, 160))\n",
    "    image = np.asarray(image).astype(\"float32\")\n",
    "    image = (image * 2/255) - 1\n",
    "    return image\n",
    "\n",
    "def get_facenet_embedding_from_paths(img_paths):\n",
    "    embeddings = [np.load(f'{path[:-4]}.npy') for path in img_paths]\n",
    "    return np.array(embeddings, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a53d9c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(val=False):\n",
    "    img_paths = copy.deepcopy(X_val_paths) if val else copy.deepcopy(X_train_paths)\n",
    "    \n",
    "    while True:\n",
    "        # shuffle\n",
    "        np.random.shuffle(img_paths)\n",
    "\n",
    "        for batch_start_i in range(0, len(img_paths), BATCH_SIZE):\n",
    "            batch_img_paths = img_paths[batch_start_i:batch_start_i+BATCH_SIZE]\n",
    "            batch_emb_paths = [os.path.join(FACENET_EMBEDDING_PATH, *img_path.split('\\\\')[-2:]) for img_path in batch_img_paths]\n",
    "            \n",
    "            batch_images = get_images_from_paths(batch_img_paths)\n",
    "            batch_facenet_embeddings = get_facenet_embedding_from_paths(batch_emb_paths)\n",
    "            yield batch_images, batch_facenet_embeddings\n",
    "\n",
    "train_generator = generate_data()\n",
    "val_generator = generate_data(val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ebf6eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_EfficientFaceNet(pretrained_path=''):\n",
    "    \n",
    "    Inp = tf.keras.layers.Input(IMG_SHAPE, name='input')\n",
    "    base_model = EfficientNetB0(include_top=False, input_tensor=Inp, drop_connect_rate=0.5)\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = tf.keras.layers.Dropout(0.5, name='dropout1')(x)\n",
    "    x = tf.keras.layers.DepthwiseConv2D((7,7), name='glb_depth_conv')(x)\n",
    "    x = tf.keras.layers.Flatten(name='flatten')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5, name='dropout2')(x)\n",
    "    x = tf.keras.layers.Dense(128, name='non_norm_emb')(x)\n",
    "    Out = tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1), name='norm_emb')(x)\n",
    "    \n",
    "    EfficientFaceNet = tf.keras.models.Model(inputs=Inp,\n",
    "                                             outputs=Out,\n",
    "                                             name='EfficientFaceNet')\n",
    "    if pretrained_path:\n",
    "        EfficientFaceNet.load_weights(pretrained_path)\n",
    "        \n",
    "    return EfficientFaceNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b14c77fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_report(model, image_preprocessing_fn, paths, labels):\n",
    "    \n",
    "    images = get_images_from_paths(paths, image_preprocessing_fn=image_preprocessing_fn)\n",
    "    embeddings = model.predict(images)\n",
    "\n",
    "    registered_embeddings, registered_labels = [], []\n",
    "    webcam_embeddings, webcam_actual_labels = [], []\n",
    "    col2label = dict()\n",
    "\n",
    "    for embedding, label in zip(embeddings, labels):\n",
    "        if label not in registered_labels:\n",
    "            registered_embeddings.append(embedding)\n",
    "            registered_labels.append(label)\n",
    "            col2label[len(col2label)] = label\n",
    "        else:\n",
    "            webcam_embeddings.append(embedding)\n",
    "            webcam_actual_labels.append(label)\n",
    "    \n",
    "    cosine_similarities = np.matmul(webcam_embeddings, np.transpose(registered_embeddings))\n",
    "\n",
    "    webcam_predicted_col = np.argmax(cosine_similarities, axis=1)\n",
    "    webcam_predicted_labels = list(map(lambda col: col2label[col], webcam_predicted_col))\n",
    "\n",
    "    webcam_actual_names = list(map(lambda lbl: lbl2name[lbl], webcam_actual_labels))\n",
    "    webcam_predicted_names = list(map(lambda lbl: lbl2name[lbl], webcam_predicted_labels))\n",
    "    \n",
    "    print(classification_report(webcam_actual_names, webcam_predicted_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e11b56",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6c8ee56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"EfficientFaceNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling (Rescaling)           (None, 224, 224, 3)  0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "normalization (Normalization)   (None, 224, 224, 3)  7           rescaling[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv_pad (ZeroPadding2D)   (None, 225, 225, 3)  0           normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 112, 112, 32) 864         stem_conv_pad[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 112, 112, 32) 128         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 112, 112, 32) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 112, 112, 32) 288         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 112, 112, 32) 128         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 112, 112, 32) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 32)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 112, 112, 32) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 112, 112, 16) 512         block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 112, 112, 16) 64          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 112, 112, 96) 1536        block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 112, 112, 96) 384         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 112, 112, 96) 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv_pad (ZeroPadding (None, 113, 113, 96) 0           block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 56, 56, 96)   864         block2a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 56, 56, 96)   384         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 56, 56, 96)   0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 96)           0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 96)     0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 4)      388         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 96)     480         block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 56, 56, 96)   0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 56, 56, 24)   2304        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 56, 56, 24)   96          block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 56, 56, 144)  3456        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 56, 56, 144)  576         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 56, 56, 144)  0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 56, 56, 144)  1296        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 56, 56, 144)  576         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 56, 56, 144)  0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 144)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 56, 56, 144)  0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 56, 56, 24)   3456        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 56, 56, 24)   96          block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (Dropout)          (None, 56, 56, 24)   0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 56, 56, 24)   0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 56, 56, 144)  3456        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 56, 56, 144)  576         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 56, 56, 144)  0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv_pad (ZeroPadding (None, 59, 59, 144)  0           block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 28, 28, 144)  3600        block3a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 28, 28, 144)  576         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 28, 28, 144)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 144)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 28, 28, 144)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 28, 28, 40)   5760        block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 28, 28, 40)   160         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 28, 28, 240)  9600        block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 28, 28, 240)  960         block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 28, 28, 240)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 28, 28, 240)  6000        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 28, 28, 240)  960         block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 28, 28, 240)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 240)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 28, 28, 240)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 28, 28, 40)   9600        block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 28, 28, 40)   160         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (Dropout)          (None, 28, 28, 40)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 28, 28, 40)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 28, 28, 240)  9600        block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 28, 28, 240)  960         block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 28, 28, 240)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv_pad (ZeroPadding (None, 29, 29, 240)  0           block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 14, 14, 240)  2160        block4a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 14, 14, 240)  960         block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 14, 14, 240)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 240)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 240)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 14, 14, 240)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 14, 14, 80)   19200       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 14, 14, 80)   320         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 14, 14, 480)  38400       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 14, 14, 480)  1920        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 14, 14, 480)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 14, 14, 480)  4320        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 14, 14, 480)  1920        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 14, 14, 480)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 480)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 14, 14, 480)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 14, 14, 80)   38400       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 14, 14, 80)   320         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (Dropout)          (None, 14, 14, 80)   0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 14, 14, 80)   0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 14, 14, 480)  38400       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 14, 14, 480)  1920        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 14, 14, 480)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 14, 14, 480)  4320        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 14, 14, 480)  1920        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 14, 14, 480)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 480)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 14, 14, 480)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 14, 14, 80)   38400       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 14, 14, 80)   320         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (Dropout)          (None, 14, 14, 80)   0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 14, 14, 80)   0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 14, 14, 480)  38400       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 14, 14, 480)  1920        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 14, 14, 480)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 14, 14, 480)  12000       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 14, 14, 480)  1920        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 14, 14, 480)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 480)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 14, 14, 480)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 14, 14, 112)  53760       block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 14, 14, 112)  448         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 14, 14, 672)  75264       block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 14, 14, 672)  2688        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 14, 14, 672)  0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 14, 14, 672)  16800       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 14, 14, 672)  2688        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 14, 14, 672)  0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 672)          0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 14, 14, 672)  0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 14, 14, 112)  75264       block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 14, 14, 112)  448         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (Dropout)          (None, 14, 14, 112)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 14, 14, 112)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 14, 14, 672)  75264       block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 14, 14, 672)  2688        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 14, 14, 672)  0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 14, 14, 672)  16800       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 14, 14, 672)  2688        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 14, 14, 672)  0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 672)          0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 14, 14, 672)  0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 14, 14, 112)  75264       block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 14, 14, 112)  448         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (Dropout)          (None, 14, 14, 112)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 14, 14, 112)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 14, 14, 672)  75264       block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 14, 14, 672)  2688        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 14, 14, 672)  0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv_pad (ZeroPadding (None, 17, 17, 672)  0           block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 7, 7, 672)    16800       block6a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 7, 7, 672)    2688        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 7, 7, 672)    0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 672)          0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 672)    0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 7, 7, 672)    0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 7, 7, 192)    129024      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 7, 7, 192)    768         block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 7, 7, 1152)   0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   28800       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 7, 7, 1152)   0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1152)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 7, 7, 1152)   0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 7, 7, 192)    221184      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 7, 7, 192)    768         block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (Dropout)          (None, 7, 7, 192)    0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 7, 7, 192)    0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 7, 7, 1152)   0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   28800       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 7, 7, 1152)   0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1152)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 7, 7, 1152)   0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 7, 7, 192)    221184      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 7, 7, 192)    768         block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (Dropout)          (None, 7, 7, 192)    0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 7, 7, 192)    0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 7, 7, 1152)   0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   28800       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 7, 7, 1152)   0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1152)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 7, 7, 1152)   0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 7, 7, 192)    221184      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 7, 7, 192)    768         block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (Dropout)          (None, 7, 7, 192)    0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 7, 7, 192)    0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 7, 7, 1152)   0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   10368       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 7, 7, 1152)   0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1152)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 7, 7, 1152)   0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 7, 7, 320)    368640      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 7, 7, 320)    1280        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 7, 7, 1280)   409600      block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 7, 7, 1280)   5120        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 7, 7, 1280)   0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 7, 7, 1280)   0           top_activation[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "glb_depth_conv (DepthwiseConv2D (None, 1, 1, 1280)   64000       dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1280)         0           glb_depth_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 1280)         0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "non_norm_emb (Dense)            (None, 128)          163968      dropout2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_emb (Lambda)               (None, 128)          0           non_norm_emb[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,277,539\n",
      "Trainable params: 4,235,516\n",
      "Non-trainable params: 42,023\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EfficientFaceNet = build_EfficientFaceNet()\n",
    "EfficientFaceNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12276d38-b256-459d-a3dd-4544262bd00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5, verbose=1),\n",
    "    tf.keras.callbacks.EarlyStopping(patience=12, restore_best_weights=True, verbose=1),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=f'{TB_LOG_PATH}'),\n",
    "    tf.keras.callbacks.CSVLogger(os.path.join(MODEL_RUN_PATH, 'training.log')),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f87553e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EfficientFaceNet.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(INITIAL_LR),\n",
    "    loss = 'cosine_similarity',\n",
    "    metrics = ['mse'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c6b0a4c-9561-4155-9340-9cb41eb35322",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngwei\\anaconda3\\envs\\tf2.6\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "331/331 [==============================] - 173s 496ms/step - loss: -0.4040 - mse: 0.9976 - val_loss: -0.5047 - val_mse: 0.9785\n",
      "Epoch 2/100\n",
      "331/331 [==============================] - 163s 491ms/step - loss: -0.6507 - mse: 0.9527 - val_loss: -0.6435 - val_mse: 0.9532\n",
      "Epoch 3/100\n",
      "331/331 [==============================] - 160s 484ms/step - loss: -0.7411 - mse: 0.9362 - val_loss: -0.7005 - val_mse: 0.9441\n",
      "Epoch 4/100\n",
      "331/331 [==============================] - 161s 485ms/step - loss: -0.7856 - mse: 0.9281 - val_loss: -0.7322 - val_mse: 0.9354\n",
      "Epoch 5/100\n",
      "331/331 [==============================] - 161s 485ms/step - loss: -0.8111 - mse: 0.9235 - val_loss: -0.7726 - val_mse: 0.9303\n",
      "Epoch 6/100\n",
      "331/331 [==============================] - 159s 482ms/step - loss: -0.8279 - mse: 0.9204 - val_loss: -0.7889 - val_mse: 0.9267\n",
      "Epoch 7/100\n",
      "331/331 [==============================] - 160s 483ms/step - loss: -0.8408 - mse: 0.9180 - val_loss: -0.7985 - val_mse: 0.9231\n",
      "Epoch 8/100\n",
      "331/331 [==============================] - 160s 484ms/step - loss: -0.8509 - mse: 0.9162 - val_loss: -0.7962 - val_mse: 0.9265\n",
      "Epoch 9/100\n",
      "331/331 [==============================] - 160s 485ms/step - loss: -0.8588 - mse: 0.9147 - val_loss: -0.8123 - val_mse: 0.9219\n",
      "Epoch 10/100\n",
      "331/331 [==============================] - 160s 483ms/step - loss: -0.8657 - mse: 0.9135 - val_loss: -0.8143 - val_mse: 0.9237\n",
      "Epoch 11/100\n",
      "331/331 [==============================] - 160s 485ms/step - loss: -0.8717 - mse: 0.9124 - val_loss: -0.8219 - val_mse: 0.9194\n",
      "Epoch 12/100\n",
      "331/331 [==============================] - 160s 484ms/step - loss: -0.8763 - mse: 0.9116 - val_loss: -0.8337 - val_mse: 0.9187\n",
      "Epoch 13/100\n",
      "331/331 [==============================] - 161s 486ms/step - loss: -0.8808 - mse: 0.9107 - val_loss: -0.8348 - val_mse: 0.9182\n",
      "Epoch 14/100\n",
      "331/331 [==============================] - 163s 492ms/step - loss: -0.8853 - mse: 0.9099 - val_loss: -0.8292 - val_mse: 0.9189\n",
      "Epoch 15/100\n",
      "331/331 [==============================] - 162s 488ms/step - loss: -0.8890 - mse: 0.9092 - val_loss: -0.8436 - val_mse: 0.9179\n",
      "Epoch 16/100\n",
      "331/331 [==============================] - 161s 485ms/step - loss: -0.8921 - mse: 0.9087 - val_loss: -0.8379 - val_mse: 0.9187\n",
      "Epoch 17/100\n",
      "331/331 [==============================] - 162s 488ms/step - loss: -0.8946 - mse: 0.9082 - val_loss: -0.8418 - val_mse: 0.9156\n",
      "Epoch 18/100\n",
      "331/331 [==============================] - 161s 486ms/step - loss: -0.8976 - mse: 0.9077 - val_loss: -0.8383 - val_mse: 0.9183\n",
      "Epoch 19/100\n",
      "331/331 [==============================] - 163s 492ms/step - loss: -0.9003 - mse: 0.9072 - val_loss: -0.8439 - val_mse: 0.9148\n",
      "Epoch 20/100\n",
      "331/331 [==============================] - 165s 498ms/step - loss: -0.9025 - mse: 0.9067 - val_loss: -0.8405 - val_mse: 0.9192\n",
      "Epoch 21/100\n",
      "331/331 [==============================] - 172s 519ms/step - loss: -0.9046 - mse: 0.9064 - val_loss: -0.8501 - val_mse: 0.9150\n",
      "Epoch 22/100\n",
      "331/331 [==============================] - 168s 508ms/step - loss: -0.9064 - mse: 0.9060 - val_loss: -0.8428 - val_mse: 0.9169\n",
      "Epoch 23/100\n",
      "331/331 [==============================] - 163s 493ms/step - loss: -0.9081 - mse: 0.9057 - val_loss: -0.8490 - val_mse: 0.9155\n",
      "Epoch 24/100\n",
      "331/331 [==============================] - 171s 518ms/step - loss: -0.9100 - mse: 0.9054 - val_loss: -0.8440 - val_mse: 0.9180\n",
      "Epoch 25/100\n",
      "331/331 [==============================] - 178s 537ms/step - loss: -0.9116 - mse: 0.9051 - val_loss: -0.8503 - val_mse: 0.9132\n",
      "Epoch 26/100\n",
      "331/331 [==============================] - 167s 503ms/step - loss: -0.9139 - mse: 0.9047 - val_loss: -0.8549 - val_mse: 0.9148\n",
      "Epoch 27/100\n",
      "331/331 [==============================] - 163s 494ms/step - loss: -0.9149 - mse: 0.9045 - val_loss: -0.8563 - val_mse: 0.9164\n",
      "Epoch 28/100\n",
      "331/331 [==============================] - 164s 495ms/step - loss: -0.9162 - mse: 0.9042 - val_loss: -0.8601 - val_mse: 0.9137\n",
      "Epoch 29/100\n",
      "331/331 [==============================] - 163s 491ms/step - loss: -0.9176 - mse: 0.9040 - val_loss: -0.8596 - val_mse: 0.9116\n",
      "Epoch 30/100\n",
      "331/331 [==============================] - 162s 491ms/step - loss: -0.9187 - mse: 0.9038 - val_loss: -0.8516 - val_mse: 0.9159\n",
      "Epoch 31/100\n",
      "331/331 [==============================] - 164s 496ms/step - loss: -0.9202 - mse: 0.9035 - val_loss: -0.8546 - val_mse: 0.9163\n",
      "Epoch 32/100\n",
      "331/331 [==============================] - 163s 491ms/step - loss: -0.9209 - mse: 0.9034 - val_loss: -0.8545 - val_mse: 0.9141\n",
      "Epoch 33/100\n",
      "331/331 [==============================] - 163s 491ms/step - loss: -0.9219 - mse: 0.9032 - val_loss: -0.8579 - val_mse: 0.9141\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 34/100\n",
      "331/331 [==============================] - 164s 496ms/step - loss: -0.9298 - mse: 0.9018 - val_loss: -0.8742 - val_mse: 0.9119\n",
      "Epoch 35/100\n",
      "331/331 [==============================] - 164s 496ms/step - loss: -0.9330 - mse: 0.9012 - val_loss: -0.8735 - val_mse: 0.9103\n",
      "Epoch 36/100\n",
      "331/331 [==============================] - 162s 491ms/step - loss: -0.9339 - mse: 0.9010 - val_loss: -0.8719 - val_mse: 0.9114\n",
      "Epoch 37/100\n",
      "331/331 [==============================] - 162s 490ms/step - loss: -0.9350 - mse: 0.9008 - val_loss: -0.8725 - val_mse: 0.9128\n",
      "Epoch 38/100\n",
      "331/331 [==============================] - 163s 492ms/step - loss: -0.9354 - mse: 0.9007 - val_loss: -0.8720 - val_mse: 0.9109\n",
      "Epoch 39/100\n",
      "331/331 [==============================] - 162s 489ms/step - loss: -0.9358 - mse: 0.9007 - val_loss: -0.8727 - val_mse: 0.9133\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 40/100\n",
      "331/331 [==============================] - 163s 492ms/step - loss: -0.9395 - mse: 0.9000 - val_loss: -0.8797 - val_mse: 0.9093\n",
      "Epoch 41/100\n",
      "331/331 [==============================] - 163s 493ms/step - loss: -0.9407 - mse: 0.8998 - val_loss: -0.8784 - val_mse: 0.9107\n",
      "Epoch 42/100\n",
      "331/331 [==============================] - 162s 489ms/step - loss: -0.9411 - mse: 0.8997 - val_loss: -0.8800 - val_mse: 0.9101\n",
      "Epoch 43/100\n",
      "331/331 [==============================] - 162s 489ms/step - loss: -0.9418 - mse: 0.8996 - val_loss: -0.8793 - val_mse: 0.9101\n",
      "Epoch 44/100\n",
      "331/331 [==============================] - 163s 492ms/step - loss: -0.9421 - mse: 0.8995 - val_loss: -0.8785 - val_mse: 0.9102\n",
      "Epoch 45/100\n",
      "331/331 [==============================] - 163s 492ms/step - loss: -0.9424 - mse: 0.8995 - val_loss: -0.8767 - val_mse: 0.9108\n",
      "Epoch 46/100\n",
      "331/331 [==============================] - 162s 491ms/step - loss: -0.9428 - mse: 0.8994 - val_loss: -0.8782 - val_mse: 0.9109\n",
      "Epoch 47/100\n",
      "331/331 [==============================] - 164s 495ms/step - loss: -0.9432 - mse: 0.8993 - val_loss: -0.8768 - val_mse: 0.9102\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 48/100\n",
      "331/331 [==============================] - 165s 498ms/step - loss: -0.9447 - mse: 0.8990 - val_loss: -0.8798 - val_mse: 0.9105\n",
      "Epoch 49/100\n",
      "331/331 [==============================] - 164s 496ms/step - loss: -0.9454 - mse: 0.8989 - val_loss: -0.8808 - val_mse: 0.9091\n",
      "Epoch 50/100\n",
      "331/331 [==============================] - 164s 495ms/step - loss: -0.9457 - mse: 0.8989 - val_loss: -0.8802 - val_mse: 0.9097\n",
      "Epoch 51/100\n",
      "331/331 [==============================] - 162s 491ms/step - loss: -0.9460 - mse: 0.8988 - val_loss: -0.8822 - val_mse: 0.9091\n",
      "Epoch 52/100\n",
      "331/331 [==============================] - 162s 489ms/step - loss: -0.9464 - mse: 0.8987 - val_loss: -0.8793 - val_mse: 0.9113\n",
      "Epoch 53/100\n",
      "331/331 [==============================] - 161s 487ms/step - loss: -0.9464 - mse: 0.8987 - val_loss: -0.8826 - val_mse: 0.9100\n",
      "Epoch 54/100\n",
      "331/331 [==============================] - 161s 488ms/step - loss: -0.9466 - mse: 0.8987 - val_loss: -0.8799 - val_mse: 0.9094\n",
      "Epoch 55/100\n",
      "331/331 [==============================] - 160s 482ms/step - loss: -0.9466 - mse: 0.8987 - val_loss: -0.8817 - val_mse: 0.9109\n",
      "Epoch 56/100\n",
      "331/331 [==============================] - 160s 484ms/step - loss: -0.9468 - mse: 0.8987 - val_loss: -0.8809 - val_mse: 0.9095\n",
      "Epoch 57/100\n",
      "331/331 [==============================] - 160s 484ms/step - loss: -0.9469 - mse: 0.8986 - val_loss: -0.8813 - val_mse: 0.9089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "331/331 [==============================] - 161s 487ms/step - loss: -0.9471 - mse: 0.8986 - val_loss: -0.8815 - val_mse: 0.9104\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 59/100\n",
      "331/331 [==============================] - 159s 481ms/step - loss: -0.9478 - mse: 0.8985 - val_loss: -0.8808 - val_mse: 0.9096\n",
      "Epoch 60/100\n",
      "331/331 [==============================] - 160s 482ms/step - loss: -0.9482 - mse: 0.8984 - val_loss: -0.8823 - val_mse: 0.9096\n",
      "Epoch 61/100\n",
      "331/331 [==============================] - 160s 484ms/step - loss: -0.9482 - mse: 0.8984 - val_loss: -0.8819 - val_mse: 0.9094\n",
      "Epoch 62/100\n",
      "331/331 [==============================] - 160s 483ms/step - loss: -0.9483 - mse: 0.8984 - val_loss: -0.8806 - val_mse: 0.9095\n",
      "Epoch 63/100\n",
      "331/331 [==============================] - 160s 483ms/step - loss: -0.9484 - mse: 0.8984 - val_loss: -0.8832 - val_mse: 0.9074\n",
      "Epoch 64/100\n",
      "331/331 [==============================] - 160s 483ms/step - loss: -0.9485 - mse: 0.8984 - val_loss: -0.8824 - val_mse: 0.9107\n",
      "Epoch 65/100\n",
      "331/331 [==============================] - 162s 489ms/step - loss: -0.9486 - mse: 0.8983 - val_loss: -0.8823 - val_mse: 0.9104\n",
      "Epoch 66/100\n",
      "331/331 [==============================] - 161s 487ms/step - loss: -0.9488 - mse: 0.8983 - val_loss: -0.8816 - val_mse: 0.9083\n",
      "Epoch 67/100\n",
      "331/331 [==============================] - 161s 485ms/step - loss: -0.9490 - mse: 0.8983 - val_loss: -0.8824 - val_mse: 0.9097\n",
      "Epoch 68/100\n",
      "331/331 [==============================] - 160s 485ms/step - loss: -0.9490 - mse: 0.8983 - val_loss: -0.8819 - val_mse: 0.9117\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 69/100\n",
      "331/331 [==============================] - 160s 484ms/step - loss: -0.9493 - mse: 0.8982 - val_loss: -0.8829 - val_mse: 0.9100\n",
      "Epoch 70/100\n",
      "331/331 [==============================] - 161s 485ms/step - loss: -0.9493 - mse: 0.8982 - val_loss: -0.8815 - val_mse: 0.9076\n",
      "Epoch 71/100\n",
      "331/331 [==============================] - 161s 485ms/step - loss: -0.9494 - mse: 0.8982 - val_loss: -0.8836 - val_mse: 0.9104\n",
      "Epoch 72/100\n",
      "331/331 [==============================] - 162s 489ms/step - loss: -0.9495 - mse: 0.8982 - val_loss: -0.8824 - val_mse: 0.9099\n",
      "Epoch 73/100\n",
      "331/331 [==============================] - 161s 488ms/step - loss: -0.9496 - mse: 0.8982 - val_loss: -0.8829 - val_mse: 0.9108\n",
      "Epoch 74/100\n",
      "331/331 [==============================] - 161s 487ms/step - loss: -0.9496 - mse: 0.8982 - val_loss: -0.8819 - val_mse: 0.9091\n",
      "Epoch 75/100\n",
      "331/331 [==============================] - 161s 487ms/step - loss: -0.9499 - mse: 0.8981 - val_loss: -0.8826 - val_mse: 0.9096\n",
      "Epoch 76/100\n",
      "331/331 [==============================] - 161s 487ms/step - loss: -0.9496 - mse: 0.8982 - val_loss: -0.8820 - val_mse: 0.9098\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 77/100\n",
      "331/331 [==============================] - 161s 486ms/step - loss: -0.9501 - mse: 0.8981 - val_loss: -0.8826 - val_mse: 0.9102\n",
      "Epoch 78/100\n",
      "331/331 [==============================] - 161s 486ms/step - loss: -0.9500 - mse: 0.8981 - val_loss: -0.8832 - val_mse: 0.9079\n",
      "Epoch 79/100\n",
      "331/331 [==============================] - 161s 486ms/step - loss: -0.9500 - mse: 0.8981 - val_loss: -0.8830 - val_mse: 0.9102\n",
      "Epoch 80/100\n",
      "331/331 [==============================] - 162s 489ms/step - loss: -0.9501 - mse: 0.8981 - val_loss: -0.8840 - val_mse: 0.9097\n",
      "Epoch 81/100\n",
      "331/331 [==============================] - 162s 490ms/step - loss: -0.9500 - mse: 0.8981 - val_loss: -0.8825 - val_mse: 0.9095\n",
      "Epoch 82/100\n",
      "331/331 [==============================] - 162s 490ms/step - loss: -0.9500 - mse: 0.8981 - val_loss: -0.8828 - val_mse: 0.9094\n",
      "Epoch 83/100\n",
      "331/331 [==============================] - 161s 486ms/step - loss: -0.9501 - mse: 0.8981 - val_loss: -0.8827 - val_mse: 0.9100\n",
      "Epoch 84/100\n",
      "331/331 [==============================] - 161s 487ms/step - loss: -0.9498 - mse: 0.8981 - val_loss: -0.8826 - val_mse: 0.9081\n",
      "Epoch 85/100\n",
      "331/331 [==============================] - 162s 489ms/step - loss: -0.9502 - mse: 0.8980 - val_loss: -0.8831 - val_mse: 0.9100\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 86/100\n",
      "331/331 [==============================] - 161s 486ms/step - loss: -0.9503 - mse: 0.8980 - val_loss: -0.8825 - val_mse: 0.9102\n",
      "Epoch 87/100\n",
      "331/331 [==============================] - 161s 486ms/step - loss: -0.9502 - mse: 0.8980 - val_loss: -0.8834 - val_mse: 0.9086\n",
      "Epoch 88/100\n",
      "331/331 [==============================] - 161s 487ms/step - loss: -0.9503 - mse: 0.8980 - val_loss: -0.8830 - val_mse: 0.9097\n",
      "Epoch 89/100\n",
      "331/331 [==============================] - 161s 486ms/step - loss: -0.9502 - mse: 0.8980 - val_loss: -0.8830 - val_mse: 0.9096\n",
      "Epoch 90/100\n",
      "331/331 [==============================] - 161s 487ms/step - loss: -0.9503 - mse: 0.8980 - val_loss: -0.8829 - val_mse: 0.9090\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 91/100\n",
      "331/331 [==============================] - 161s 487ms/step - loss: -0.9504 - mse: 0.8980 - val_loss: -0.8832 - val_mse: 0.9088\n",
      "Epoch 92/100\n",
      "331/331 [==============================] - 162s 490ms/step - loss: -0.9502 - mse: 0.8980 - val_loss: -0.8825 - val_mse: 0.9101\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00092: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24d70f0e5e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EfficientFaceNet.fit(\n",
    "    train_generator,\n",
    "    validation_data = val_generator,\n",
    "    epochs = EPOCHS,\n",
    "    steps_per_epoch = np.ceil(len(X_train_paths) / BATCH_SIZE),\n",
    "    validation_steps = np.ceil(len(X_val_paths) / BATCH_SIZE),\n",
    "    callbacks = callbacks,\n",
    "    verbose = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3941070c-3120-4091-8c77-4ad0e1133975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(EfficientFaceNet.history, os.path.join(MODEL_RUN_PATH, f'training_plot_{MODEL_NAME}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a469816",
   "metadata": {},
   "outputs": [],
   "source": [
    "EfficientFaceNet.save_weights(os.path.join(MODEL_RUN_PATH, f'savedweights_{MODEL_NAME}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedbbd07",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8bf0568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x25011af1d90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EfficientFaceNet = build_EfficientFaceNet()\n",
    "EfficientFaceNet.load_weights(os.path.join(MODEL_RUN_PATH, f'savedweights_{MODEL_NAME}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "047669bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "    alastair_campbell       1.00      1.00      1.00         4\n",
      "         alice_fisher       1.00      1.00      1.00         1\n",
      "        allyson_felix       1.00      1.00      1.00         4\n",
      "alvaro_silva_calderon       0.33      1.00      0.50         3\n",
      "         alvaro_uribe       1.00      0.88      0.94        34\n",
      "anders_fogh_rasmussen       0.30      1.00      0.46         3\n",
      "         andrew_cuomo       0.33      1.00      0.50         1\n",
      "          ann_veneman       0.77      1.00      0.87        10\n",
      "       annette_bening       0.06      1.00      0.12         1\n",
      "      anthony_hopkins       0.33      1.00      0.50         1\n",
      "     antonio_banderas       1.00      0.25      0.40         4\n",
      "arnold_schwarzenegger       1.00      0.63      0.78        41\n",
      "     aung_san_suu_kyi       0.50      1.00      0.67         1\n",
      "           barry_zito       0.00      0.00      0.00         1\n",
      "          ben_howland       1.00      1.00      1.00         3\n",
      "          bernard_law       0.38      0.75      0.50         4\n",
      "         carlos_vives       0.33      1.00      0.50         3\n",
      "       carmen_electra       1.00      0.60      0.75         5\n",
      "     caroline_kennedy       0.67      1.00      0.80         2\n",
      "      cecilia_bolocco       0.50      0.50      0.50         2\n",
      "          chan_gailey       1.00      1.00      1.00         2\n",
      "       chang_dae_whan       0.00      0.00      0.00         1\n",
      "         chita_rivera       1.00      1.00      1.00         1\n",
      "           chris_rock       1.00      1.00      1.00         1\n",
      " christian_fittipaldi       0.50      1.00      0.67         1\n",
      "   christopher_patten       0.33      1.00      0.50         1\n",
      "       cindy_margolis       0.17      1.00      0.29         1\n",
      "        darren_clarke       0.00      0.00      0.00         1\n",
      "         daryl_hannah       0.10      1.00      0.18         1\n",
      "    david_hyde_pierce       0.50      0.33      0.40         3\n",
      "          david_myers       1.00      1.00      1.00         1\n",
      "           david_wolf       1.00      1.00      1.00         1\n",
      "      donald_rumsfeld       1.00      0.92      0.96       120\n",
      "          eddy_merckx       0.50      1.00      0.67         1\n",
      "        edwin_edwards       0.67      1.00      0.80         2\n",
      "          eliane_karp       0.12      0.33      0.18         3\n",
      "          elijah_wood       0.11      1.00      0.20         2\n",
      "      elizabeth_olsen       0.81      0.76      0.79       220\n",
      "          eric_rosser       0.25      1.00      0.40         1\n",
      "      federico_trillo       0.67      1.00      0.80         2\n",
      "         fidel_castro       0.92      0.71      0.80        17\n",
      "    franz_beckenbauer       0.00      0.00      0.00         1\n",
      "        fred_thompson       0.67      1.00      0.80         2\n",
      "         gary_winnick       1.00      1.00      1.00         1\n",
      "       george_clooney       0.73      1.00      0.84         8\n",
      "         george_lopez       0.57      1.00      0.73         4\n",
      "          george_ryan       0.00      0.00      0.00         3\n",
      "        george_w_bush       1.00      0.97      0.99       529\n",
      "     gillian_anderson       0.33      1.00      0.50         1\n",
      "        greg_rusedski       1.00      1.00      1.00         3\n",
      "      gwyneth_paltrow       0.96      0.86      0.91       192\n",
      "           heidi_klum       0.33      1.00      0.50         4\n",
      "   henrique_meirelles       1.00      1.00      1.00         1\n",
      "              hun_sen       0.40      0.67      0.50         3\n",
      "      ibrahim_jaafari       1.00      1.00      1.00         1\n",
      "       jack_nicholson       0.00      0.00      0.00         2\n",
      "          james_smith       0.50      1.00      0.67         1\n",
      "       jamling_norgay       0.50      1.00      0.67         1\n",
      "           jay_garner       0.62      1.00      0.77         5\n",
      "             jay_leno       0.67      1.00      0.80         2\n",
      "        jean_chretien       0.93      0.96      0.95        54\n",
      "   jean_david_levitte       0.80      0.89      0.84         9\n",
      "       jeffrey_immelt       0.33      1.00      0.50         1\n",
      "    jennifer_connelly       0.17      1.00      0.29         3\n",
      "             jim_hahn       1.00      1.00      1.00         3\n",
      "         jodie_foster       1.00      1.00      1.00         2\n",
      "  john_allen_muhammad       0.91      1.00      0.95        10\n",
      "          john_blaney       0.50      1.00      0.67         1\n",
      "           john_kerry       1.00      1.00      1.00        16\n",
      "      john_negroponte       0.97      0.93      0.95        30\n",
      "        john_stockton       1.00      0.50      0.67         4\n",
      "           john_walsh       1.00      1.00      1.00         1\n",
      "          johnny_depp       1.00      0.23      0.37       181\n",
      "      jorge_castaneda       0.25      1.00      0.40         1\n",
      "        jorge_valdano       0.50      1.00      0.67         1\n",
      "         jose_canseco       1.00      0.50      0.67         2\n",
      "          jose_sarney       1.00      0.50      0.67         2\n",
      "           jose_serra       0.67      1.00      0.80         8\n",
      " juan_valencia_osorio       1.00      1.00      1.00         1\n",
      "        justin_gatlin       0.00      0.00      0.00         1\n",
      "       kathleen_glynn       0.14      1.00      0.25         1\n",
      "        kim_clijsters       0.76      1.00      0.87        13\n",
      "         kirk_johnson       1.00      1.00      1.00         2\n",
      "        klaus_zwickel       0.50      1.00      0.67         1\n",
      "  kristen_breitweiser       0.67      1.00      0.80         2\n",
      "         kurt_russell       1.00      1.00      1.00         1\n",
      "        lana_clarkson       0.25      1.00      0.40         1\n",
      "        lauren_hutton       0.33      1.00      0.50         1\n",
      "         leander_paes       0.33      1.00      0.50         1\n",
      "         lebron_james       1.00      1.00      1.00         4\n",
      "     lesley_mcculloch       1.00      1.00      1.00         2\n",
      "        lili_reinhart       0.79      0.31      0.44       147\n",
      "          lili_taylor       0.50      1.00      0.67         1\n",
      "         lionel_messi       1.00      0.90      0.95        84\n",
      "           lon_kruger       1.00      1.00      1.00         1\n",
      "    luciano_pavarotti       0.29      1.00      0.44         2\n",
      "           mack_brown       1.00      1.00      1.00         1\n",
      "      maisie_williams       0.93      0.75      0.83       192\n",
      "    margaret_thatcher       0.50      1.00      0.67         1\n",
      " maria_luisa_mendonca       1.00      1.00      1.00         1\n",
      "        maria_pedraza       0.62      0.87      0.72       120\n",
      "      mariana_pollack       1.00      1.00      1.00         2\n",
      "        mark_wahlberg       0.50      0.33      0.40         3\n",
      "    mathias_reichhold       0.20      1.00      0.33         2\n",
      "        matthew_perry       0.25      1.00      0.40         6\n",
      "megawati_sukarnoputri       1.00      0.97      0.98        32\n",
      "        michel_duclos       1.00      1.00      1.00         1\n",
      "        michelle_kwan       0.75      0.86      0.80         7\n",
      "    michelle_pfeiffer       0.00      0.00      0.00         2\n",
      "   michelle_rodriguez       0.10      1.00      0.18         1\n",
      "       miguel_estrada       0.00      0.00      0.00         1\n",
      "      morena_baccarin       0.98      0.99      0.98       174\n",
      "          naomi_watts       0.76      0.90      0.83        21\n",
      "            naoto_kan       1.00      1.00      1.00         3\n",
      "   olesya_bonabarenko       0.50      1.00      0.67         1\n",
      "   olivia_newton_john       0.10      1.00      0.18         1\n",
      "        orlando_bloom       0.06      0.50      0.10         2\n",
      "        ozzy_osbourne       1.00      0.50      0.67         2\n",
      "        patrick_ewing       1.00      1.00      1.00         1\n",
      "   paul_henri_mathieu       1.00      1.00      1.00         2\n",
      "     pervez_musharraf       0.94      1.00      0.97        17\n",
      "         peter_arnett       0.67      1.00      0.80         2\n",
      "     pierre_boulanger       0.20      1.00      0.33         1\n",
      "       prince_charles       1.00      0.75      0.86         4\n",
      "     rachel_griffiths       0.67      1.00      0.80         2\n",
      "raghad_saddam_hussein       0.20      1.00      0.33         1\n",
      "      renee_zellweger       0.52      0.69      0.59        16\n",
      "   ricardo_monasterio       1.00      1.00      1.00         1\n",
      "      ricardo_sanchez       0.80      0.80      0.80         5\n",
      "       richard_crenna       1.00      1.00      1.00         1\n",
      "        richard_myers       0.89      0.94      0.91        17\n",
      "        rio_ferdinand       0.00      0.00      0.00         1\n",
      "            roy_moore       0.50      0.60      0.55         5\n",
      "      russell_simmons       1.00      0.75      0.86         4\n",
      "       sally_kirkland       1.00      0.67      0.80         3\n",
      "          salma_hayek       0.86      1.00      0.92        12\n",
      "      scott_mcclellan       0.80      1.00      0.89         4\n",
      "         scott_ritter       0.50      1.00      0.67         1\n",
      "   sebastien_grosjean       0.16      1.00      0.27         3\n",
      "          shane_warne       0.00      0.00      0.00         1\n",
      "       shannon_obrien       0.33      1.00      0.50         1\n",
      "           stan_heath       1.00      1.00      1.00         1\n",
      "         stanley_tong       0.50      1.00      0.67         1\n",
      "       steven_hatfill       0.20      1.00      0.33         1\n",
      "        steven_seagal       0.50      1.00      0.67         1\n",
      "  taha_yassin_ramadan       0.92      0.86      0.89        14\n",
      "  tammy_lynn_michaels       0.25      1.00      0.40         1\n",
      "          theresa_may       0.00      0.00      0.00         2\n",
      "            tim_curry       0.20      1.00      0.33         1\n",
      "        tracy_mcgrady       1.00      1.00      1.00         1\n",
      "        tung_chee_hwa       0.00      0.00      0.00         8\n",
      "       valdas_adamkus       1.00      1.00      1.00         1\n",
      "     vanessa_williams       0.20      0.50      0.29         2\n",
      "     victoria_beckham       0.00      0.00      0.00         2\n",
      "         vince_carter       1.00      1.00      1.00         3\n",
      "      william_bratton       1.00      1.00      1.00         2\n",
      "         yukiko_okudo       0.00      0.00      0.00         1\n",
      "     yuri_malenchenko       1.00      1.00      1.00         1\n",
      "           zhang_ziyi       0.00      0.00      0.00         3\n",
      "                 zico       1.00      1.00      1.00         2\n",
      "\n",
      "             accuracy                           0.80      2599\n",
      "            macro avg       0.62      0.82      0.65      2599\n",
      "         weighted avg       0.89      0.80      0.81      2599\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngwei\\anaconda3\\envs\\tf2.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ngwei\\anaconda3\\envs\\tf2.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ngwei\\anaconda3\\envs\\tf2.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "get_report(EfficientFaceNet, image_preprocessing, X_val_paths, y_val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38692678",
   "metadata": {},
   "source": [
    "# Embedding Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15a1aa47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x25047196310>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EfficientFaceNet = build_EfficientFaceNet()\n",
    "EfficientFaceNet.load_weights(os.path.join(MODEL_RUN_PATH, f'savedweights_{MODEL_NAME}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "653a99c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://projector.tensorflow.org/\n",
    "\n",
    "# Evaluate the network\n",
    "np.random.seed(1234)\n",
    "labels, counts = np.unique(y_val_labels, return_counts=True)\n",
    "candidates_sample_labels = [lbl for lbl, cnt in zip(labels, counts) if cnt >= 10]\n",
    "selected_sample_labels = np.random.choice(candidates_sample_labels, 10, replace=False)\n",
    "\n",
    "X_sample_paths = [path for path, label in zip(X_val_paths, y_val_labels) if label in selected_sample_labels]\n",
    "y_sample_labels = [label for label in y_val_labels if label in selected_sample_labels]\n",
    "\n",
    "sample_images = get_images_from_paths(X_sample_paths)\n",
    "val_results = EfficientFaceNet.predict(sample_images)\n",
    "\n",
    "# Save test embeddings for visualization in projector\n",
    "np.savetxt(os.path.join(MODEL_RUN_PATH, f'val_embedding_results_{MODEL_NAME}.tsv'), val_results, delimiter='\\t')\n",
    "\n",
    "out_m = io.open(os.path.join(MODEL_RUN_PATH, f'val_embedding_meta_{MODEL_NAME}.tsv'), 'w', encoding='utf-8')\n",
    "for img, label in zip(sample_images, y_sample_labels):\n",
    "    [out_m.write(str(lbl2name[label]) + \"\\n\")]\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc57bd9",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "543d20f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x250896e8c70>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EfficientFaceNet = build_EfficientFaceNet()\n",
    "EfficientFaceNet.load_weights(os.path.join(MODEL_RUN_PATH, f'savedweights_{MODEL_NAME}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf3cc671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "         abdel_nasser_assidi       0.00      0.00      0.00         1\n",
      "                    abdullah       0.43      1.00      0.60         3\n",
      "            abdullatif_sener       0.20      1.00      0.33         1\n",
      "abid_hamid_mahmud_al_tikriti       0.50      1.00      0.67         2\n",
      "              adrian_nastase       0.33      1.00      0.50         1\n",
      "                adrien_brody       0.83      0.91      0.87        11\n",
      "                   al_pacino       0.67      1.00      0.80         2\n",
      "                alan_mulally       0.25      1.00      0.40         1\n",
      "                albert_costa       0.67      0.80      0.73         5\n",
      "                   alex_sink       1.00      1.00      1.00         2\n",
      "                 amanda_crew       0.94      0.97      0.95       116\n",
      "               amer_al_saadi       1.00      1.00      1.00         3\n",
      "                amram_mitzna       0.00      0.00      0.00         1\n",
      "                andy_roddick       0.90      0.64      0.75        14\n",
      "                antony_leung       0.75      1.00      0.86         3\n",
      "          arianna_huffington       0.75      1.00      0.86         3\n",
      "            barbra_streisand       1.00      1.00      1.00         2\n",
      "              benazir_bhutto       0.67      1.00      0.80         4\n",
      "               bill_sizemore       1.00      1.00      1.00         1\n",
      "                   bo_pelini       1.00      1.00      1.00         1\n",
      "              brendan_hansen       0.50      1.00      0.67         1\n",
      "                 brian_cowen       1.00      1.00      1.00         1\n",
      "                 carla_myers       0.25      1.00      0.40         1\n",
      "                 carlos_ruiz       0.14      0.50      0.22         2\n",
      "                 chris_evans       0.89      0.78      0.83       165\n",
      "       christine_baumgartner       0.40      1.00      0.57         4\n",
      "              chung_mong_hun       0.00      0.00      0.00         1\n",
      "                  ciro_gomes       0.57      1.00      0.73         4\n",
      "                  clay_aiken       0.36      1.00      0.53         5\n",
      "              clint_eastwood       1.00      1.00      1.00         5\n",
      "               courtney_love       0.17      1.00      0.29         1\n",
      "          cristina_fernandez       0.00      0.00      0.00         1\n",
      "            daniel_radcliffe       0.33      1.00      0.50         3\n",
      "                 diane_green       0.33      1.00      0.50         1\n",
      "            dianne_feinstein       0.33      1.00      0.50         2\n",
      "                donald_evans       0.50      1.00      0.67         1\n",
      "           donatella_versace       0.33      1.00      0.50         2\n",
      "               dorthy_moxley       0.50      1.00      0.67         1\n",
      "                eddie_sutton       0.20      1.00      0.33         1\n",
      "               emily_robison       0.00      0.00      0.00         1\n",
      "                  emma_stone       0.60      0.47      0.53       137\n",
      "                 eric_hinske       0.00      0.00      0.00         1\n",
      "           evander_holyfield       1.00      1.00      1.00         1\n",
      "                 ferenc_madl       0.25      1.00      0.40         1\n",
      "   fernando_henrique_cardoso       1.00      1.00      1.00         7\n",
      "              franco_dragone       0.33      1.00      0.50         1\n",
      "               gary_williams       0.50      1.00      0.67         1\n",
      "               geno_auriemma       1.00      1.00      1.00         1\n",
      "               george_p_bush       1.00      1.00      1.00         1\n",
      "           george_papandreou       1.00      1.00      1.00         3\n",
      "            gerard_depardieu       0.09      1.00      0.17         1\n",
      "             gerardo_gambala       1.00      1.00      1.00         1\n",
      "               goran_persson       0.33      1.00      0.50         1\n",
      "               grant_hackett       1.00      1.00      1.00         4\n",
      "                  gray_davis       0.95      0.84      0.89        25\n",
      "             guillermo_coria       0.96      0.86      0.91        29\n",
      "             guillermo_ortiz       0.25      1.00      0.40         1\n",
      "                  hal_sutton       0.25      1.00      0.40         1\n",
      "                  hamzah_haz       0.50      1.00      0.67         1\n",
      "           hannah_stockbauer       0.25      1.00      0.40         1\n",
      "             harry_belafonte       0.33      1.00      0.50         1\n",
      "              hayley_tullett       0.25      1.00      0.40         1\n",
      "              hipolito_mejia       1.00      1.00      1.00         3\n",
      "               horst_koehler       0.50      0.50      0.50         2\n",
      "               hosni_mubarak       0.73      1.00      0.84         8\n",
      "                 james_butts       1.00      1.00      1.00         1\n",
      "               james_maguire       1.00      1.00      1.00         1\n",
      "             james_mcgreevey       0.29      0.67      0.40         3\n",
      "                  jane_fonda       0.00      0.00      0.00         1\n",
      "                 jane_pauley       1.00      1.00      1.00         1\n",
      "              jason_jennings       0.25      1.00      0.40         1\n",
      "                javier_weber       0.50      1.00      0.67         2\n",
      "               jean_carnahan       0.50      1.00      0.67         1\n",
      "                  jeff_bezos       0.98      0.98      0.98       101\n",
      "             jefferson_perez       0.09      1.00      0.17         1\n",
      "       jeffrey_scott_postell       0.17      1.00      0.29         1\n",
      "                jelena_dokic       0.21      0.71      0.32         7\n",
      "           jennifer_lawrence       0.92      0.81      0.86       178\n",
      "               jeremy_renner       0.98      0.90      0.94       165\n",
      "               jerry_falwell       0.14      1.00      0.25         1\n",
      "                jessica_alba       0.14      1.00      0.25         1\n",
      "                   joe_torre       0.60      1.00      0.75         3\n",
      "                joerg_haider       0.20      1.00      0.33         1\n",
      "                 john_jumper       0.25      1.00      0.40         1\n",
      "                 john_mccain       1.00      1.00      1.00         6\n",
      "                john_paul_ii       1.00      1.00      1.00        10\n",
      "             john_stallworth       1.00      1.00      1.00         1\n",
      "           johnson_panjaitan       1.00      1.00      1.00         1\n",
      "              joseph_ralston       1.00      1.00      1.00         1\n",
      "                julie_taymor       0.33      1.00      0.50         1\n",
      "           junichiro_koizumi       1.00      0.76      0.87        59\n",
      "                keith_bogans       1.00      1.00      1.00         2\n",
      "              kimi_raikkonen       0.50      1.00      0.67         2\n",
      "                 kurt_warner       1.00      1.00      1.00         4\n",
      "                  lance_bass       0.40      1.00      0.57         4\n",
      "                  laura_bush       1.00      0.75      0.86        40\n",
      "             laura_hernandez       0.20      1.00      0.33         1\n",
      "                laura_linney       0.60      1.00      0.75         3\n",
      "               lee_hoi_chang       1.00      1.00      1.00         3\n",
      "               lee_soo_hyuck       1.00      1.00      1.00         2\n",
      "         leslie_ann_woodward       0.17      1.00      0.29         1\n",
      "              leslie_moonves       0.50      1.00      0.67         1\n",
      "                 li_zhaoxing       0.83      0.71      0.77         7\n",
      "        lina_krasnoroutskaya       0.20      1.00      0.33         1\n",
      "               lindsay_benko       0.25      1.00      0.40         1\n",
      "                liu_mingkang       1.00      1.00      1.00         1\n",
      "              lleyton_hewitt       0.91      0.78      0.84        40\n",
      "                  luis_horna       0.44      0.80      0.57         5\n",
      "         luiz_felipe_scolari       0.50      1.00      0.67         1\n",
      "   luiz_inacio_lula_da_silva       0.92      0.98      0.95        47\n",
      "       marco_antonio_barrera       0.56      1.00      0.71         5\n",
      "       marie_reine_le_gougne       1.00      1.00      1.00         1\n",
      "           marieta_chrousala       0.20      1.00      0.33         2\n",
      "              martin_brodeur       1.00      1.00      1.00         1\n",
      "              martin_cauchon       0.25      1.00      0.40         1\n",
      "             martin_mccauley       0.50      1.00      0.67         1\n",
      "           martin_mcguinness       1.00      1.00      1.00         4\n",
      "             martin_scorsese       0.00      0.00      0.00         6\n",
      "           matthew_broderick       0.00      0.00      0.00         3\n",
      "            melanie_griffith       0.04      0.50      0.08         2\n",
      "            michael_capellas       1.00      1.00      1.00         1\n",
      "               michael_chang       0.64      1.00      0.78         7\n",
      "             michael_douglas       0.62      1.00      0.77         5\n",
      "              michael_powell       1.00      1.00      1.00         4\n",
      "            michelle_collins       0.10      1.00      0.18         1\n",
      "                   mike_weir       1.00      0.90      0.95        10\n",
      "                 miley_cyrus       0.91      0.68      0.78       176\n",
      "           milo_maestrecampo       1.00      1.00      1.00         2\n",
      "                    miroljub       0.33      1.00      0.50         1\n",
      "             monica_lewinsky       0.29      1.00      0.44         2\n",
      "              naomi_campbell       0.25      1.00      0.40         1\n",
      "               nathalie_baye       0.43      1.00      0.60         3\n",
      "              nicolas_escude       0.50      1.00      0.67         1\n",
      "                 norah_jones       0.08      0.36      0.12        14\n",
      "                norm_coleman       0.60      1.00      0.75         6\n",
      "           parris_glendening       0.50      1.00      0.67         1\n",
      "             patrick_stewart       0.00      0.00      0.00         1\n",
      "              patty_schnyder       0.43      1.00      0.60         3\n",
      "                 paul_coppin       0.25      1.00      0.40         1\n",
      "              paul_gascoigne       0.67      1.00      0.80         2\n",
      "              paul_wellstone       1.00      0.50      0.67         2\n",
      "              paul_wolfowitz       0.90      1.00      0.95         9\n",
      "                pedro_solbes       0.60      1.00      0.75         3\n",
      "             raymond_odierno       0.33      1.00      0.50         1\n",
      "       rebecca_romijn_stamos       0.08      0.67      0.14         3\n",
      "                ricky_martin       0.33      1.00      0.50         1\n",
      "                 rita_grande       1.00      1.00      1.00         2\n",
      "              robert_de_niro       0.91      0.26      0.41       160\n",
      "            robert_downey_jr       0.95      0.70      0.81       232\n",
      "           robinson_stevenin       0.10      1.00      0.18         1\n",
      "              rogerio_romero       0.17      1.00      0.29         1\n",
      "                rolf_eckrodt       1.00      1.00      1.00         1\n",
      "                roy_williams       0.67      0.67      0.67         3\n",
      "                 s_jayakumar       0.50      1.00      0.67         1\n",
      "            saburo_kawabuchi       0.10      1.00      0.18         1\n",
      "                 sheryl_crow       0.88      1.00      0.93         7\n",
      "                sophia_loren       0.83      0.83      0.83         6\n",
      "             stephen_ambrose       0.00      0.00      0.00         1\n",
      "            stephen_friedman       0.50      1.00      0.67         1\n",
      "                 steve_lavin       0.38      1.00      0.56         5\n",
      "              strom_thurmond       0.00      0.00      0.00         2\n",
      "              taufik_hidayat       0.40      1.00      0.57         2\n",
      "                   ted_maher       0.33      1.00      0.50         1\n",
      "                terry_stotts       0.14      1.00      0.25         1\n",
      "                 tony_curtis       1.00      1.00      1.00         1\n",
      "                 tony_parker       0.00      0.00      0.00         1\n",
      "              ursula_corbero       0.94      0.70      0.80       165\n",
      "                vaclav_klaus       0.00      0.00      0.00         1\n",
      "              vidar_helgesen       1.00      1.00      1.00         1\n",
      "            vitali_klitschko       0.15      1.00      0.26         3\n",
      "              walter_mondale       0.56      1.00      0.72         9\n",
      "               warren_beatty       0.33      1.00      0.50         1\n",
      "               wayne_gretzky       1.00      1.00      1.00         3\n",
      "             william_ford_jr       0.62      0.83      0.71         6\n",
      "      zafarullah_khan_jamali       0.50      1.00      0.67         1\n",
      "                     zendaya       0.88      0.82      0.85       136\n",
      "                  zhu_rongji       1.00      1.00      1.00         8\n",
      "                 zoe_saldana       0.98      0.53      0.69       183\n",
      "\n",
      "                    accuracy                           0.74      2564\n",
      "                   macro avg       0.56      0.87      0.62      2564\n",
      "                weighted avg       0.87      0.74      0.77      2564\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngwei\\anaconda3\\envs\\tf2.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ngwei\\anaconda3\\envs\\tf2.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ngwei\\anaconda3\\envs\\tf2.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "get_report(EfficientFaceNet, image_preprocessing, X_test_paths, y_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407bf19a",
   "metadata": {},
   "source": [
    "# Compare with Facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdf52011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngwei\\anaconda3\\envs\\tf2.6\\lib\\site-packages\\keras\\layers\\core.py:1043: UserWarning: keras.layers.core.lambda_layer is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  warnings.warn('{} is not loaded, but a Lambda layer uses it. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "FaceNet = tf.keras.models.load_model(os.path.join(BASE_PATH, 'models', 'FaceNet', 'facenet_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b84b82f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "         abdel_nasser_assidi       0.00      0.00      0.00         1\n",
      "                    abdullah       0.75      1.00      0.86         3\n",
      "            abdullatif_sener       0.11      1.00      0.20         1\n",
      "abid_hamid_mahmud_al_tikriti       1.00      1.00      1.00         2\n",
      "              adrian_nastase       1.00      1.00      1.00         1\n",
      "                adrien_brody       1.00      0.91      0.95        11\n",
      "                   al_pacino       0.33      1.00      0.50         2\n",
      "                alan_mulally       0.50      1.00      0.67         1\n",
      "                albert_costa       1.00      1.00      1.00         5\n",
      "                   alex_sink       0.50      1.00      0.67         2\n",
      "                 amanda_crew       0.99      0.97      0.98       116\n",
      "               amer_al_saadi       0.75      1.00      0.86         3\n",
      "                amram_mitzna       0.00      0.00      0.00         1\n",
      "                andy_roddick       0.93      1.00      0.97        14\n",
      "                antony_leung       1.00      1.00      1.00         3\n",
      "          arianna_huffington       1.00      1.00      1.00         3\n",
      "            barbra_streisand       1.00      1.00      1.00         2\n",
      "              benazir_bhutto       0.80      1.00      0.89         4\n",
      "               bill_sizemore       1.00      1.00      1.00         1\n",
      "                   bo_pelini       0.50      1.00      0.67         1\n",
      "              brendan_hansen       1.00      1.00      1.00         1\n",
      "                 brian_cowen       1.00      1.00      1.00         1\n",
      "                 carla_myers       1.00      1.00      1.00         1\n",
      "                 carlos_ruiz       0.50      0.50      0.50         2\n",
      "                 chris_evans       0.98      0.86      0.92       165\n",
      "       christine_baumgartner       0.12      1.00      0.21         4\n",
      "              chung_mong_hun       0.00      0.00      0.00         1\n",
      "                  ciro_gomes       0.57      1.00      0.73         4\n",
      "                  clay_aiken       0.62      1.00      0.77         5\n",
      "              clint_eastwood       0.71      1.00      0.83         5\n",
      "               courtney_love       0.33      1.00      0.50         1\n",
      "          cristina_fernandez       0.00      0.00      0.00         1\n",
      "            daniel_radcliffe       0.75      1.00      0.86         3\n",
      "                 diane_green       1.00      1.00      1.00         1\n",
      "            dianne_feinstein       0.67      1.00      0.80         2\n",
      "                donald_evans       1.00      1.00      1.00         1\n",
      "           donatella_versace       0.25      1.00      0.40         2\n",
      "               dorthy_moxley       0.50      1.00      0.67         1\n",
      "                eddie_sutton       1.00      1.00      1.00         1\n",
      "               emily_robison       0.00      0.00      0.00         1\n",
      "                  emma_stone       0.97      0.62      0.76       137\n",
      "                 eric_hinske       0.20      1.00      0.33         1\n",
      "           evander_holyfield       0.50      1.00      0.67         1\n",
      "                 ferenc_madl       1.00      1.00      1.00         1\n",
      "   fernando_henrique_cardoso       0.88      1.00      0.93         7\n",
      "              franco_dragone       0.50      1.00      0.67         1\n",
      "               gary_williams       0.50      1.00      0.67         1\n",
      "               geno_auriemma       1.00      1.00      1.00         1\n",
      "               george_p_bush       1.00      1.00      1.00         1\n",
      "           george_papandreou       1.00      1.00      1.00         3\n",
      "            gerard_depardieu       0.08      1.00      0.15         1\n",
      "             gerardo_gambala       1.00      1.00      1.00         1\n",
      "               goran_persson       1.00      1.00      1.00         1\n",
      "               grant_hackett       0.80      1.00      0.89         4\n",
      "                  gray_davis       1.00      0.92      0.96        25\n",
      "             guillermo_coria       1.00      0.97      0.98        29\n",
      "             guillermo_ortiz       1.00      1.00      1.00         1\n",
      "                  hal_sutton       1.00      1.00      1.00         1\n",
      "                  hamzah_haz       1.00      1.00      1.00         1\n",
      "           hannah_stockbauer       0.50      1.00      0.67         1\n",
      "             harry_belafonte       1.00      1.00      1.00         1\n",
      "              hayley_tullett       0.33      1.00      0.50         1\n",
      "              hipolito_mejia       1.00      1.00      1.00         3\n",
      "               horst_koehler       1.00      1.00      1.00         2\n",
      "               hosni_mubarak       0.89      1.00      0.94         8\n",
      "                 james_butts       1.00      1.00      1.00         1\n",
      "               james_maguire       1.00      1.00      1.00         1\n",
      "             james_mcgreevey       0.43      1.00      0.60         3\n",
      "                  jane_fonda       0.20      1.00      0.33         1\n",
      "                 jane_pauley       1.00      1.00      1.00         1\n",
      "              jason_jennings       1.00      1.00      1.00         1\n",
      "                javier_weber       1.00      1.00      1.00         2\n",
      "               jean_carnahan       1.00      1.00      1.00         1\n",
      "                  jeff_bezos       1.00      0.99      1.00       101\n",
      "             jefferson_perez       0.50      1.00      0.67         1\n",
      "       jeffrey_scott_postell       1.00      1.00      1.00         1\n",
      "                jelena_dokic       0.43      0.86      0.57         7\n",
      "           jennifer_lawrence       0.98      0.91      0.94       178\n",
      "               jeremy_renner       0.99      0.98      0.99       165\n",
      "               jerry_falwell       0.14      1.00      0.25         1\n",
      "                jessica_alba       0.33      1.00      0.50         1\n",
      "                   joe_torre       0.75      1.00      0.86         3\n",
      "                joerg_haider       0.33      1.00      0.50         1\n",
      "                 john_jumper       1.00      1.00      1.00         1\n",
      "                 john_mccain       1.00      1.00      1.00         6\n",
      "                john_paul_ii       1.00      1.00      1.00        10\n",
      "             john_stallworth       0.00      0.00      0.00         1\n",
      "           johnson_panjaitan       1.00      1.00      1.00         1\n",
      "              joseph_ralston       1.00      1.00      1.00         1\n",
      "                julie_taymor       0.50      1.00      0.67         1\n",
      "           junichiro_koizumi       0.98      0.98      0.98        59\n",
      "                keith_bogans       1.00      1.00      1.00         2\n",
      "              kimi_raikkonen       0.67      1.00      0.80         2\n",
      "                 kurt_warner       0.80      1.00      0.89         4\n",
      "                  lance_bass       0.33      1.00      0.50         4\n",
      "                  laura_bush       1.00      0.97      0.99        40\n",
      "             laura_hernandez       0.50      1.00      0.67         1\n",
      "                laura_linney       0.60      1.00      0.75         3\n",
      "               lee_hoi_chang       1.00      1.00      1.00         3\n",
      "               lee_soo_hyuck       0.67      1.00      0.80         2\n",
      "         leslie_ann_woodward       0.33      1.00      0.50         1\n",
      "              leslie_moonves       1.00      1.00      1.00         1\n",
      "                 li_zhaoxing       0.83      0.71      0.77         7\n",
      "        lina_krasnoroutskaya       0.50      1.00      0.67         1\n",
      "               lindsay_benko       0.33      1.00      0.50         1\n",
      "                liu_mingkang       1.00      1.00      1.00         1\n",
      "              lleyton_hewitt       0.98      1.00      0.99        40\n",
      "                  luis_horna       0.56      1.00      0.71         5\n",
      "         luiz_felipe_scolari       1.00      1.00      1.00         1\n",
      "   luiz_inacio_lula_da_silva       1.00      0.98      0.99        47\n",
      "       marco_antonio_barrera       0.83      1.00      0.91         5\n",
      "       marie_reine_le_gougne       1.00      1.00      1.00         1\n",
      "           marieta_chrousala       0.67      1.00      0.80         2\n",
      "              martin_brodeur       1.00      1.00      1.00         1\n",
      "              martin_cauchon       0.50      1.00      0.67         1\n",
      "             martin_mccauley       1.00      1.00      1.00         1\n",
      "           martin_mcguinness       1.00      1.00      1.00         4\n",
      "             martin_scorsese       0.00      0.00      0.00         6\n",
      "           matthew_broderick       0.33      0.33      0.33         3\n",
      "            melanie_griffith       0.25      1.00      0.40         2\n",
      "            michael_capellas       1.00      1.00      1.00         1\n",
      "               michael_chang       0.88      1.00      0.93         7\n",
      "             michael_douglas       0.71      1.00      0.83         5\n",
      "              michael_powell       1.00      0.75      0.86         4\n",
      "            michelle_collins       0.14      1.00      0.25         1\n",
      "                   mike_weir       0.83      1.00      0.91        10\n",
      "                 miley_cyrus       1.00      0.93      0.96       176\n",
      "           milo_maestrecampo       0.40      1.00      0.57         2\n",
      "                    miroljub       0.25      1.00      0.40         1\n",
      "             monica_lewinsky       0.67      1.00      0.80         2\n",
      "              naomi_campbell       0.50      1.00      0.67         1\n",
      "               nathalie_baye       0.38      1.00      0.55         3\n",
      "              nicolas_escude       0.50      1.00      0.67         1\n",
      "                 norah_jones       0.92      0.86      0.89        14\n",
      "                norm_coleman       0.86      1.00      0.92         6\n",
      "           parris_glendening       1.00      1.00      1.00         1\n",
      "             patrick_stewart       0.00      0.00      0.00         1\n",
      "              patty_schnyder       1.00      1.00      1.00         3\n",
      "                 paul_coppin       1.00      1.00      1.00         1\n",
      "              paul_gascoigne       0.67      1.00      0.80         2\n",
      "              paul_wellstone       1.00      1.00      1.00         2\n",
      "              paul_wolfowitz       1.00      1.00      1.00         9\n",
      "                pedro_solbes       1.00      1.00      1.00         3\n",
      "             raymond_odierno       0.50      1.00      0.67         1\n",
      "       rebecca_romijn_stamos       0.18      0.67      0.29         3\n",
      "                ricky_martin       0.33      1.00      0.50         1\n",
      "                 rita_grande       1.00      1.00      1.00         2\n",
      "              robert_de_niro       0.95      0.46      0.62       160\n",
      "            robert_downey_jr       1.00      0.89      0.94       232\n",
      "           robinson_stevenin       0.25      1.00      0.40         1\n",
      "              rogerio_romero       0.33      1.00      0.50         1\n",
      "                rolf_eckrodt       0.50      1.00      0.67         1\n",
      "                roy_williams       1.00      1.00      1.00         3\n",
      "                 s_jayakumar       0.50      1.00      0.67         1\n",
      "            saburo_kawabuchi       1.00      1.00      1.00         1\n",
      "                 sheryl_crow       0.88      1.00      0.93         7\n",
      "                sophia_loren       1.00      0.83      0.91         6\n",
      "             stephen_ambrose       0.00      0.00      0.00         1\n",
      "            stephen_friedman       0.00      0.00      0.00         1\n",
      "                 steve_lavin       0.31      1.00      0.48         5\n",
      "              strom_thurmond       1.00      1.00      1.00         2\n",
      "              taufik_hidayat       0.50      1.00      0.67         2\n",
      "                   ted_maher       1.00      1.00      1.00         1\n",
      "                terry_stotts       1.00      1.00      1.00         1\n",
      "                 tony_curtis       0.50      1.00      0.67         1\n",
      "                 tony_parker       0.25      1.00      0.40         1\n",
      "              ursula_corbero       0.96      0.92      0.94       165\n",
      "                vaclav_klaus       0.00      0.00      0.00         1\n",
      "              vidar_helgesen       1.00      1.00      1.00         1\n",
      "            vitali_klitschko       0.14      1.00      0.25         3\n",
      "              walter_mondale       0.75      1.00      0.86         9\n",
      "               warren_beatty       0.17      1.00      0.29         1\n",
      "               wayne_gretzky       0.75      1.00      0.86         3\n",
      "             william_ford_jr       0.83      0.83      0.83         6\n",
      "      zafarullah_khan_jamali       1.00      1.00      1.00         1\n",
      "                     zendaya       1.00      0.94      0.97       136\n",
      "                  zhu_rongji       1.00      1.00      1.00         8\n",
      "                 zoe_saldana       0.99      0.93      0.96       183\n",
      "\n",
      "                    accuracy                           0.89      2564\n",
      "                   macro avg       0.71      0.91      0.76      2564\n",
      "                weighted avg       0.95      0.89      0.90      2564\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngwei\\anaconda3\\envs\\tf2.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ngwei\\anaconda3\\envs\\tf2.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ngwei\\anaconda3\\envs\\tf2.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "get_report(FaceNet, image_facenet_preprocessing, X_test_paths, y_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca1e6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
